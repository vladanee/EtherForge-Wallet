import { JsonRpcProvider, WebSocketProvider } from '@ethersproject/providers';
import { BigNumber } from '@ethersproject/bignumber';
import SturdyWebSocket from 'sturdy-websocket';
import axios from 'axios';

/**
 * The supported networks by Alchemy. Note that some functions are not available
 * on all networks. Please refer to the Alchemy documentation for more details.
 *
 * @public
 */
var Network;
(function (Network) {
    Network["ETH_MAINNET"] = "eth-mainnet";
    Network["ETH_ROPSTEN"] = "eth-ropsten";
    Network["ETH_GOERLI"] = "eth-goerli";
    Network["ETH_KOVAN"] = "eth-kovan";
    Network["ETH_RINKEBY"] = "eth-rinkeby";
    Network["OPT_MAINNET"] = "opt-mainnet";
    Network["OPT_KOVAN"] = "opt-kovan";
    Network["ARB_MAINNET"] = "arb-mainnet";
    Network["ARB_RINKEBY"] = "arb-rinkeby";
    Network["MATIC_MAINNET"] = "polygon-mainnet";
    Network["MATIC_MUMBAI"] = "polygon-mumbai";
})(Network || (Network = {}));
/** @public */
var AssetTransfersCategory;
(function (AssetTransfersCategory) {
    AssetTransfersCategory["EXTERNAL"] = "external";
    AssetTransfersCategory["INTERNAL"] = "internal";
    AssetTransfersCategory["TOKEN"] = "token";
    AssetTransfersCategory["ERC20"] = "erc20";
    AssetTransfersCategory["ERC721"] = "erc721";
    AssetTransfersCategory["ERC1155"] = "erc1155";
    /**
     * Special contracts that don't follow ERC 721/1155, (ex: CryptoKitties).
     *
     * @beta
     */
    AssetTransfersCategory["SPECIALNFT"] = "specialnft";
})(AssetTransfersCategory || (AssetTransfersCategory = {}));
/** @public */
var AssetTransfersOrder;
(function (AssetTransfersOrder) {
    AssetTransfersOrder["ASCENDING"] = "asc";
    AssetTransfersOrder["DESCENDING"] = "desc";
})(AssetTransfersOrder || (AssetTransfersOrder = {}));
/** @public */
var NftTokenType;
(function (NftTokenType) {
    NftTokenType["ERC721"] = "ERC721";
    NftTokenType["ERC1155"] = "ERC1155";
    NftTokenType["UNKNOWN"] = "UNKNOWN";
})(NftTokenType || (NftTokenType = {}));
/**
 * Enum of NFT filters that can be applied to a {@link getNftsForOwner} request.
 * NFTs that match one or more of these filters are excluded from the response.
 *
 * @beta
 */
var NftExcludeFilters;
(function (NftExcludeFilters) {
    /** Exclude NFTs that have been classified as spam. */
    NftExcludeFilters["SPAM"] = "SPAM";
})(NftExcludeFilters || (NftExcludeFilters = {}));

const DEFAULT_CONTRACT_ADDRESSES = 'DEFAULT_TOKENS';
const DEFAULT_ALCHEMY_API_KEY = 'demo';
const DEFAULT_NETWORK = Network.ETH_MAINNET;
const DEFAULT_MAX_RETRIES = 5;
/**
 * Returns the base URL for making Alchemy API requests. The `alchemy.com`
 * endpoints only work with non eth json-rpc requests.
 *
 * @internal
 */
function getAlchemyHttpUrl(network, apiKey) {
    return `https://${network}.g.alchemy.com/v2/${apiKey}`;
}
function getAlchemyNftHttpUrl(network, apiKey) {
    return `https://${network}.g.alchemy.com/nft/v2/${apiKey}`;
}
function getAlchemyWsUrl(network, apiKey) {
    return `wss://${network}.g.alchemy.com/v2/${apiKey}`;
}
var AlchemyApiType;
(function (AlchemyApiType) {
    AlchemyApiType[AlchemyApiType["BASE"] = 0] = "BASE";
    AlchemyApiType[AlchemyApiType["NFT"] = 1] = "NFT";
})(AlchemyApiType || (AlchemyApiType = {}));
/**
 * Mapping of network names to their corresponding Network strings used to
 * create an Ethers.js Provider instance.
 */
const EthersNetwork = {
    [Network.ETH_MAINNET]: 'mainnet',
    [Network.ETH_ROPSTEN]: 'ropsten',
    [Network.ETH_GOERLI]: 'goerli',
    [Network.ETH_KOVAN]: 'kovan',
    [Network.ETH_RINKEBY]: 'rinkeby',
    [Network.OPT_MAINNET]: 'optimism',
    [Network.OPT_KOVAN]: 'optimism-kovan',
    [Network.ARB_MAINNET]: 'arbitrum',
    [Network.ARB_RINKEBY]: 'arbitrum-rinkeby',
    [Network.MATIC_MAINNET]: 'matic',
    [Network.MATIC_MUMBAI]: 'maticmum'
};
function noop() {
    // It's a no-op
}

/*! *****************************************************************************
Copyright (c) Microsoft Corporation.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
***************************************************************************** */

function __awaiter(thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
}

function __values(o) {
    var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
    if (m) return m.call(o);
    if (o && typeof o.length === "number") return {
        next: function () {
            if (o && i >= o.length) o = void 0;
            return { value: o && o[i++], done: !o };
        }
    };
    throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
}

function __await(v) {
    return this instanceof __await ? (this.v = v, this) : new __await(v);
}

function __asyncGenerator(thisArg, _arguments, generator) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var g = generator.apply(thisArg, _arguments || []), i, q = [];
    return i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i;
    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }
    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }
    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }
    function fulfill(value) { resume("next", value); }
    function reject(value) { resume("throw", value); }
    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }
}

function __asyncValues(o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i);
    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }
    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }
}

/**
 * The SDK has 4 log levels and a 5th option for disabling all logging. By
 * default, the log level is set to INFO.
 *
 * The order is a follows: DEBUG < INFO < WARN < ERROR
 *
 * All log types above the current log level will be outputted.
 */
var LogLevel;
(function (LogLevel) {
    LogLevel[LogLevel["DEBUG"] = 0] = "DEBUG";
    LogLevel[LogLevel["INFO"] = 1] = "INFO";
    LogLevel[LogLevel["WARN"] = 2] = "WARN";
    LogLevel[LogLevel["ERROR"] = 3] = "ERROR";
    LogLevel[LogLevel["SILENT"] = 4] = "SILENT";
})(LogLevel || (LogLevel = {}));
const logLevelStringToEnum = {
    debug: LogLevel.DEBUG,
    info: LogLevel.INFO,
    warn: LogLevel.WARN,
    error: LogLevel.ERROR,
    silent: LogLevel.SILENT
};
// HACKY: Use the console method as a string rather than the function itself
// in order to allow for mocking in tests.
const logLevelToConsoleFn = {
    [LogLevel.DEBUG]: 'log',
    [LogLevel.INFO]: 'info',
    [LogLevel.WARN]: 'warn',
    [LogLevel.ERROR]: 'error'
};
const DEFAULT_LOG_LEVEL = LogLevel.INFO;
/**
 * Configures the verbosity of logging. The default log level is `info`.
 *
 * @param logLevel - The verbosity of logging. Can be any of the following values:
 *
 *   - `debug`: The most verbose logging level.
 *   - `info`: The default logging level.
 *   - `warn`: A logging level for non-critical issues.
 *   - `error`: A logging level for critical issues.
 *   - `silent`: Turn off all logging.
 *
 * @public
 */
function setLogLevel(logLevel) {
    loggerClient.logLevel = logLevelStringToEnum[logLevel];
}
function logDebug(message, ...args) {
    loggerClient.debug(message, args);
}
function logInfo(message, ...args) {
    loggerClient.info(message, args);
}
function logWarn(message, ...args) {
    loggerClient.warn(message, args);
}
class Logger {
    constructor() {
        /** The log level of the given Logger instance. */
        this._logLevel = DEFAULT_LOG_LEVEL;
    }
    get logLevel() {
        return this._logLevel;
    }
    set logLevel(val) {
        if (!(val in LogLevel)) {
            throw new TypeError(`Invalid value "${val}" assigned to \`logLevel\``);
        }
        this._logLevel = val;
    }
    debug(...args) {
        this._log(LogLevel.DEBUG, ...args);
    }
    info(...args) {
        this._log(LogLevel.INFO, ...args);
    }
    warn(...args) {
        this._log(LogLevel.WARN, ...args);
    }
    error(...args) {
        this._log(LogLevel.ERROR, ...args);
    }
    /**
     * Forwards log messages to their corresponding console counterparts if the
     * log level allows it.
     */
    _log(logLevel, ...args) {
        if (logLevel < this._logLevel) {
            return;
        }
        const now = new Date().toISOString();
        const method = logLevelToConsoleFn[logLevel];
        if (method) {
            console[method](`[${now}] Alchemy:`, ...args.map(stringify));
        }
        else {
            throw new Error(`Logger received an invalid logLevel (value: ${logLevel})`);
        }
    }
}
function stringify(obj) {
    if (typeof obj === 'string') {
        return obj;
    }
    else {
        try {
            return JSON.stringify(obj);
        }
        catch (e) {
            // Failed to convert to JSON, log the object directly.
            return obj;
        }
    }
}
// Instantiate default logger for the SDK.
const loggerClient = new Logger();

// This file is autogenerated by injectVersion.js. Any changes will be
// overwritten on commit!
const VERSION = '1.1.1';

/**
 * SDK's custom implementation of ethers.js's 'AlchemyProvider'.
 *
 * @public
 */
class AlchemyProvider extends JsonRpcProvider {
    constructor(network, apiKey, maxRetries) {
        // Normalize the API Key to a string.
        apiKey = AlchemyProvider.getApiKey(apiKey);
        // Generate our own connection info with the correct endpoint URLs.
        const alchemyNetwork = AlchemyProvider.getAlchemyNetwork(network);
        const connection = AlchemyProvider.getAlchemyConnectionInfo(alchemyNetwork, apiKey, 'http');
        // Normalize the Alchemy named network input to the network names used by
        // ethers. This allows the parent super constructor in JsonRpcProvider to
        // correctly set the network.
        const ethersNetwork = EthersNetwork[alchemyNetwork];
        super(connection, ethersNetwork);
        this.apiKey = apiKey;
        this.maxRetries = maxRetries;
    }
    /**
     * Overrides the `UrlJsonRpcProvider.getApiKey` method as implemented by
     * ethers.js. Returns the API key for an Alchemy provider.
     *
     * @internal
     * @override
     */
    static getApiKey(apiKey) {
        if (apiKey == null) {
            return DEFAULT_ALCHEMY_API_KEY;
        }
        if (apiKey && typeof apiKey !== 'string') {
            throw new Error(`Invalid apiKey '${apiKey}' provided. apiKey must be a string.`);
        }
        return apiKey;
    }
    /**
     * Converts the `Networkish` input to the network enum used by Alchemy.
     *
     * @internal
     */
    static getAlchemyNetwork(network) {
        if (network === undefined) {
            return DEFAULT_NETWORK;
        }
        if (typeof network === 'number') {
            throw new Error(`Invalid network '${network}' provided. Network must be a string.`);
        }
        // Guaranteed that `typeof network === 'string`.
        const isValidNetwork = Object.values(Network).includes(network);
        if (!isValidNetwork) {
            throw new Error(`Invalid network '${network}' provided. Network must be one of: ` +
                `${Object.values(Network).join(', ')}.`);
        }
        return network;
    }
    /**
     * Returns a {@link ConnectionInfo} object compatible with ethers that contains
     * the correct URLs for Alchemy.
     *
     * @internal
     */
    static getAlchemyConnectionInfo(network, apiKey, type) {
        const url = type === 'http'
            ? getAlchemyHttpUrl(network, apiKey)
            : getAlchemyWsUrl(network, apiKey);
        return {
            headers: {
                'Alchemy-Ethers-Sdk-Version': VERSION,
                'Accept-Encoding': 'gzip'
            },
            allowGzip: true,
            url
        };
    }
    /**
     * Overrides the method in ethers.js's `StaticJsonRpcProvider` class. This
     * method is called when calling methods on the parent class `BaseProvider`.
     *
     * @override
     */
    detectNetwork() {
        const _super = Object.create(null, {
            detectNetwork: { get: () => super.detectNetwork }
        });
        return __awaiter(this, void 0, void 0, function* () {
            let network = this.network;
            if (network == null) {
                network = yield _super.detectNetwork.call(this);
                if (!network) {
                    throw new Error('No network detected');
                }
            }
            return network;
        });
    }
    _startPending() {
        logWarn('WARNING: Alchemy Provider does not support pending filters');
    }
    /**
     * Overrides the ether's `isCommunityResource()` method. Returns true if the
     * current api key is the default key.
     *
     * @override
     */
    isCommunityResource() {
        return this.apiKey === DEFAULT_ALCHEMY_API_KEY;
    }
    /**
     * Overrides the base {@link JsonRpcProvider.send} method to implement custom
     * logic for sending requests to Alchemy.
     *
     * @param method The method name to use for the request.
     * @param params The parameters to use for the request.
     * @override
     * @public
     */
    // TODO: Implement sender logic to override retries and backoff.
    send(method, params) {
        return super.send(method, params);
    }
}

/**
 * Converts a hex string to a decimal number.
 *
 * @param hexString - The hex string to convert.
 * @public
 */
function fromHex(hexString) {
    return BigNumber.from(hexString).toNumber();
}
/**
 * Converts a number to a hex string.
 *
 * @param num - The number to convert to hex.
 * @public
 */
function toHex(num) {
    return BigNumber.from(num).toHexString();
}
/**
 * Checks if a value is a hex string.
 *
 * @param possibleHexString - The value to check.
 * @public
 */
function isHex(possibleHexString) {
    return /^0x[0-9a-fA-F]+$/.test(possibleHexString);
}

/**
 * The maximum number of blocks to backfill. If more than this many blocks have
 * been missed, then we'll sadly miss data, but we want to make sure we don't
 * end up requesting thousands of blocks if somebody left their laptop closed for a week.
 */
const MAX_BACKFILL_BLOCKS = 120;
/**
 * The WebsocketBackfiller fetches events that were sent since a provided block
 * number. This is used in the {@link AlchemyWebSocketProvider} to backfill
 * events that were transmitted while the websocket connection was down.
 *
 * The backfiller backfills two main eth_subscribe events: `logs` and `newHeads`.
 *
 * @internal
 */
class WebsocketBackfiller {
    constructor(provider) {
        this.provider = provider;
        // TODO: Use HTTP provider to do backfill.
        this.maxBackfillBlocks = MAX_BACKFILL_BLOCKS;
    }
    /**
     * Runs backfill for `newHeads` events.
     *
     * @param isCancelled Whether the backfill request is cancelled.
     * @param previousHeads Previous head requests that were sent.
     * @param fromBlockNumber The block number to start backfilling from.
     * @returns A list of `newHeads` events that were sent since the last backfill.
     */
    getNewHeadsBackfill(isCancelled, previousHeads, fromBlockNumber) {
        return __awaiter(this, void 0, void 0, function* () {
            throwIfCancelled(isCancelled);
            const toBlockNumber = yield this.getBlockNumber();
            throwIfCancelled(isCancelled);
            // If there are no previous heads to fetch, return new heads since
            // `fromBlockNumber`, or up to maxBackfillBlocks from the current head.
            if (previousHeads.length === 0) {
                return this.getHeadEventsInRange(Math.max(fromBlockNumber, toBlockNumber - this.maxBackfillBlocks) + 1, toBlockNumber + 1);
            }
            // If the last emitted event is too far back in the past, there's no need
            // to backfill for reorgs. Just fetch the last `maxBackfillBlocks` worth of
            // new heads.
            const lastSeenBlockNumber = fromHex(previousHeads[previousHeads.length - 1].number);
            const minBlockNumber = toBlockNumber - this.maxBackfillBlocks + 1;
            if (lastSeenBlockNumber <= minBlockNumber) {
                return this.getHeadEventsInRange(minBlockNumber, toBlockNumber + 1);
            }
            // To capture all `newHeads` events, return all head events from the last
            // seen block number to current + any of the previous heads that were re-orged.
            const reorgHeads = yield this.getReorgHeads(isCancelled, previousHeads);
            throwIfCancelled(isCancelled);
            const intermediateHeads = yield this.getHeadEventsInRange(lastSeenBlockNumber + 1, toBlockNumber + 1);
            throwIfCancelled(isCancelled);
            return [...reorgHeads, ...intermediateHeads];
        });
    }
    /**
     * Runs backfill for `logs` events.
     *
     * @param isCancelled Whether the backfill request is cancelled.
     * @param filter The filter object that accompanies a logs subscription.
     * @param previousLogs Previous log requests that were sent.
     * @param fromBlockNumber The block number to start backfilling from.
     */
    getLogsBackfill(isCancelled, filter, previousLogs, fromBlockNumber) {
        return __awaiter(this, void 0, void 0, function* () {
            throwIfCancelled(isCancelled);
            const toBlockNumber = yield this.getBlockNumber();
            throwIfCancelled(isCancelled);
            // If there are no previous logs to fetch, return new logs since
            // `fromBlockNumber`, or up to `maxBackfillBlocks` from the current head.
            if (previousLogs.length === 0) {
                return this.getLogsInRange(filter, Math.max(fromBlockNumber, toBlockNumber - this.maxBackfillBlocks) + 1, toBlockNumber + 1);
            }
            // If the last emitted log is too far back in the past, there's no need
            // to backfill for removed logs. Just fetch the last `maxBackfillBlocks`
            // worth of logs.
            const lastSeenBlockNumber = fromHex(previousLogs[previousLogs.length - 1].blockNumber);
            const minBlockNumber = toBlockNumber - this.maxBackfillBlocks + 1;
            if (lastSeenBlockNumber < minBlockNumber) {
                return this.getLogsInRange(filter, minBlockNumber, toBlockNumber + 1);
            }
            // Return all log events that have happened along with log events that have
            // been removed due to a chain reorg.
            const commonAncestor = yield this.getCommonAncestor(isCancelled, previousLogs);
            throwIfCancelled(isCancelled);
            // All previous logs with a block number greater than the common ancestor
            // were part of a re-org, so mark them as such.
            const removedLogs = previousLogs
                .filter(log => fromHex(log.blockNumber) > commonAncestor.blockNumber)
                .map(log => (Object.assign(Object.assign({}, log), { removed: true })));
            // If no common ancestor was found, start backfill from the oldest log's
            // block number.
            const fromBlockInclusive = commonAncestor.blockNumber === Number.NEGATIVE_INFINITY
                ? fromHex(previousLogs[0].blockNumber)
                : commonAncestor.blockNumber;
            let addedLogs = yield this.getLogsInRange(filter, fromBlockInclusive, toBlockNumber + 1);
            // De-dupe any logs that were already emitted.
            addedLogs = addedLogs.filter(log => log &&
                (fromHex(log.blockNumber) > commonAncestor.blockNumber ||
                    fromHex(log.logIndex) > commonAncestor.logIndex));
            throwIfCancelled(isCancelled);
            return [...removedLogs, ...addedLogs];
        });
    }
    /**
     * Sets a new max backfill blocks. VISIBLE ONLY FOR TESTING.
     *
     * @internal
     */
    setMaxBackfillBlock(newMax) {
        this.maxBackfillBlocks = newMax;
    }
    /**
     * Gets the current block number as a number.
     *
     * @private
     */
    getBlockNumber() {
        return __awaiter(this, void 0, void 0, function* () {
            const blockNumberHex = yield this.provider.send('eth_blockNumber');
            return fromHex(blockNumberHex);
        });
    }
    /**
     * Gets all `newHead` events in the provided range. Note that the returned
     * heads do not include re-orged heads. Use {@link getReorgHeads} to find heads
     * that were part of a re-org.
     *
     * @private
     */
    getHeadEventsInRange(fromBlockInclusive, toBlockExclusive) {
        return __awaiter(this, void 0, void 0, function* () {
            if (fromBlockInclusive >= toBlockExclusive) {
                return [];
            }
            const batchParts = [];
            for (let i = fromBlockInclusive; i < toBlockExclusive; i++) {
                batchParts.push({
                    method: 'eth_getBlockByNumber',
                    params: [toHex(i), false]
                });
            }
            // TODO: just fire off each send() separately since we're no longer batching:
            // TODO: handle errors
            const batchedBlockHeads = yield this.provider.sendBatch(batchParts);
            const blockHeads = batchedBlockHeads.reduce((acc, batch) => acc.concat(batch), []);
            return blockHeads.map(toNewHeadsEvent);
        });
    }
    /**
     * Returns all heads that were part of a reorg event.
     *
     * @private
     */
    getReorgHeads(isCancelled, previousHeads) {
        return __awaiter(this, void 0, void 0, function* () {
            const result = [];
            // Iterate from the most recent head backwards in order to find the first
            // block that was part of a re-org.
            for (let i = previousHeads.length - 1; i >= 0; i--) {
                const oldEvent = previousHeads[i];
                const blockHead = yield this.getBlockByNumber(fromHex(oldEvent.number));
                throwIfCancelled(isCancelled);
                // If the hashes match, then current head in the iteration was not re-orged.
                if (oldEvent.hash === blockHead.hash) {
                    break;
                }
                result.push(toNewHeadsEvent(blockHead));
            }
            return result.reverse();
        });
    }
    /**
     * Simple wrapper around `eth_getBlockByNumber` that returns the complete
     * block information for the provided block number.
     *
     * @private
     */
    getBlockByNumber(blockNumber) {
        return __awaiter(this, void 0, void 0, function* () {
            return this.provider.send('eth_getBlockByNumber', [
                toHex(blockNumber),
                false
            ]);
        });
    }
    /**
     * Given a list of previous log events, finds the common block number from the
     * logs that matches the block head.
     *
     * This can be used to identify which logs are part of a re-org.
     *
     * Returns 1 less than the oldest log's block number if no common ancestor was found.
     *
     * @private
     */
    getCommonAncestor(isCancelled, previousLogs) {
        return __awaiter(this, void 0, void 0, function* () {
            // Iterate from the most recent head backwards in order to find the first
            // block that was part of a re-org.
            let blockHead = yield this.getBlockByNumber(fromHex(previousLogs[previousLogs.length - 1].blockNumber));
            throwIfCancelled(isCancelled);
            for (let i = previousLogs.length - 1; i >= 0; i--) {
                const oldLog = previousLogs[i];
                // Ensure that updated blocks are fetched every time the log's block number
                // changes.
                if (oldLog.blockNumber !== blockHead.number) {
                    blockHead = yield this.getBlockByNumber(fromHex(oldLog.blockNumber));
                }
                // Since logs are ordered in ascending order, the first log that matches
                // the hash should be the largest logIndex.
                if (oldLog.blockHash === blockHead.hash) {
                    return {
                        blockNumber: fromHex(oldLog.blockNumber),
                        logIndex: fromHex(oldLog.logIndex)
                    };
                }
            }
            return {
                blockNumber: Number.NEGATIVE_INFINITY,
                logIndex: Number.NEGATIVE_INFINITY
            };
        });
    }
    /**
     * Gets all `logs` events in the provided range. Note that the returned logs
     * do not include removed logs.
     *
     * @private
     */ getLogsInRange(filter, fromBlockInclusive, toBlockExclusive) {
        return __awaiter(this, void 0, void 0, function* () {
            if (fromBlockInclusive >= toBlockExclusive) {
                return [];
            }
            const rangeFilter = Object.assign(Object.assign({}, filter), { fromBlock: toHex(fromBlockInclusive), toBlock: toHex(toBlockExclusive - 1) });
            return this.provider.send('eth_getLogs', [rangeFilter]);
        });
    }
}
function toNewHeadsEvent(head) {
    const result = Object.assign({}, head);
    delete result.totalDifficulty;
    delete result.transactions;
    delete result.uncles;
    return result;
}
function dedupeNewHeads(events) {
    return dedupe(events, event => event.hash);
}
function dedupeLogs(events) {
    return dedupe(events, event => `${event.blockHash}/${event.logIndex}`);
}
function dedupe(items, getKey) {
    const keysSeen = new Set();
    const result = [];
    items.forEach(item => {
        const key = getKey(item);
        if (!keysSeen.has(key)) {
            keysSeen.add(key);
            result.push(item);
        }
    });
    return result;
}
const CANCELLED = new Error('Cancelled');
function throwIfCancelled(isCancelled) {
    if (isCancelled()) {
        throw CANCELLED;
    }
}

/**
 * DO NOT MODIFY.
 *
 * Event class copied directly over from ethers.js's `BaseProvider` class.
 *
 * This class is used to represent events and their corresponding listeners. The
 * SDK needs to extend this class in order to support Alchemy's custom
 * Subscription API types. The original class is not exported by ethers. Minimal
 * changes have been made in order to get TS to compile.
 */
class Event {
    constructor(tag, listener, once) {
        this.listener = listener;
        this.tag = tag;
        this.once = once;
        this._lastBlockNumber = -2;
        this._inflight = false;
    }
    get event() {
        switch (this.type) {
            case 'tx':
                return this.hash;
            case 'filter':
                return this.filter;
            default:
                return this.tag;
        }
    }
    get type() {
        return this.tag.split(':')[0];
    }
    get hash() {
        const comps = this.tag.split(':');
        if (comps[0] !== 'tx') {
            throw new Error('Not a transaction event');
        }
        return comps[1];
    }
    get filter() {
        const comps = this.tag.split(':');
        if (comps[0] !== 'filter') {
            throw new Error('Not a transaction event');
        }
        const address = comps[1];
        const topics = deserializeTopics(comps[2]);
        const filter = {};
        if (topics.length > 0) {
            filter.topics = topics;
        }
        if (address && address !== '*') {
            filter.address = address;
        }
        return filter;
    }
    pollable() {
        const PollableEvents = ['block', 'network', 'pending', 'poll'];
        return this.tag.indexOf(':') >= 0 || PollableEvents.indexOf(this.tag) >= 0;
    }
}
/**
 * Wrapper class around the ethers `Event` class in order to add support for
 * Alchemy's custom subscriptions types.
 */
class EthersEvent extends Event {
    get address() {
        const comps = this.tag.split(':');
        if (comps[0] !== 'alchemy') {
            return null;
        }
        if (comps[1] && comps[1] !== '*') {
            return comps[1];
        }
        else {
            return null;
        }
    }
}
function deserializeTopics(data) {
    if (data === '') {
        return [];
    }
    return data.split(/&/g).map(topic => {
        if (topic === '') {
            return [];
        }
        const comps = topic.split('|').map(topic => {
            return topic === 'null' ? null : topic;
        });
        return comps.length === 1 ? comps[0] : comps;
    });
}

const HEARTBEAT_INTERVAL = 30000;
const HEARTBEAT_WAIT_TIME = 10000;
const BACKFILL_TIMEOUT = 60000;
const BACKFILL_RETRIES = 5;
/**
 * Subscriptions have a memory of recent events they have sent so that in the
 * event that they disconnect and need to backfill, they can detect re-orgs.
 * Keep a buffer that goes back at least these many blocks, the maximum amount
 * at which we might conceivably see a re-org.
 *
 * Note that while our buffer goes back this many blocks, it may contain more
 * than this many elements, since in the case of logs subscriptions more than
 * one event may be emitted for a block.
 */
const RETAINED_EVENT_BLOCK_COUNT = 10;
class AlchemyWebSocketProvider extends WebSocketProvider {
    /**
     * DO NOT CALL THIS CONSTRUCTOR DIRECTLY. Instead, use `Alchemy.getWebsocketProvider()`.
     *
     * @param network Requires one of the Alchemy `Network` enums
     * @param apiKey The api key, or defaults to `demo`.
     * @param wsConstructor Optional WebSocket constructor. Currently, used only
     *   for testing purposes.
     * @internal
     */
    constructor(network, apiKey, wsConstructor) {
        // Normalize the API Key to a string.
        apiKey = AlchemyProvider.getApiKey(apiKey);
        // Generate our own connection info with the correct endpoint URLs.
        const alchemyNetwork = AlchemyProvider.getAlchemyNetwork(network);
        const connection = AlchemyProvider.getAlchemyConnectionInfo(alchemyNetwork, apiKey, 'wss');
        const protocol = `alchemy-sdk-${VERSION}`;
        const ws = new SturdyWebSocket(connection.url, protocol, {
            wsConstructor: wsConstructor !== null && wsConstructor !== void 0 ? wsConstructor : getWebsocketConstructor()
        });
        // Normalize the Alchemy named network input to the network names used by
        // ethers. This allows the parent super constructor in JsonRpcProvider to
        // correctly set the network.
        const ethersNetwork = EthersNetwork[alchemyNetwork];
        super(ws, ethersNetwork);
        this._events = [];
        // In the case of a WebSocket reconnection, all subscriptions are lost and we
        // create new ones to replace them, but we want to create the illusion that
        // the original subscriptions persist. Thus, maintain a mapping from the
        // "virtual" subscription ids which are visible to the consumer to the
        // "physical" subscription ids of the actual connections. This terminology is
        // borrowed from virtual and physical memory, which has a similar mapping.
        /** @internal */
        this.virtualSubscriptionsById = new Map();
        /** @internal */
        this.virtualIdsByPhysicalId = new Map();
        /**
         * The underlying ethers {@link WebSocketProvider} already handles and emits
         * messages. To allow backfilling, track all messages that are emitted.
         *
         * This is a field arrow function in order to preserve `this` context when
         * passing the method as an event listener.
         *
         * @internal
         */
        this.handleMessage = (event) => {
            const message = JSON.parse(event.data);
            if (!isSubscriptionEvent(message)) {
                return;
            }
            const physicalId = message.params.subscription;
            const virtualId = this.virtualIdsByPhysicalId.get(physicalId);
            if (!virtualId) {
                return;
            }
            const subscription = this.virtualSubscriptionsById.get(virtualId);
            if (subscription.method !== 'eth_subscribe') {
                return;
            }
            switch (subscription.params[0]) {
                case 'newHeads': {
                    const newHeadsSubscription = subscription;
                    const newHeadsMessage = message;
                    const { isBackfilling, backfillBuffer } = newHeadsSubscription;
                    const { result } = newHeadsMessage.params;
                    if (isBackfilling) {
                        addToNewHeadsEventsBuffer(backfillBuffer, result);
                    }
                    else if (physicalId !== virtualId) {
                        // In the case of a re-opened subscription, ethers will not emit the
                        // event, so the SDK has to.
                        this.emitAndRememberEvent(virtualId, result, getNewHeadsBlockNumber);
                    }
                    else {
                        // Ethers subscription mapping will emit the event, just store it.
                        this.rememberEvent(virtualId, result, getNewHeadsBlockNumber);
                    }
                    break;
                }
                case 'logs': {
                    const logsSubscription = subscription;
                    const logsMessage = message;
                    const { isBackfilling, backfillBuffer } = logsSubscription;
                    const { result } = logsMessage.params;
                    if (isBackfilling) {
                        addToLogsEventsBuffer(backfillBuffer, result);
                    }
                    else if (virtualId !== physicalId) {
                        this.emitAndRememberEvent(virtualId, result, getLogsBlockNumber);
                    }
                    else {
                        this.rememberEvent(virtualId, result, getLogsBlockNumber);
                    }
                    break;
                }
            }
        };
        /**
         * When the websocket connection reopens:
         *
         * 1. Resubscribe to all existing subscriptions and start backfilling
         * 2. Restart heart beat.
         *
         * This is a field arrow function in order to preserve `this` context when
         * passing the method as an event listener.
         *
         * @internal
         */
        this.handleReopen = () => {
            this.virtualIdsByPhysicalId.clear();
            const { cancel, isCancelled } = makeCancelToken();
            this.cancelBackfill = cancel;
            for (const subscription of this.virtualSubscriptionsById.values()) {
                void (() => __awaiter(this, void 0, void 0, function* () {
                    try {
                        yield this.resubscribeAndBackfill(isCancelled, subscription);
                    }
                    catch (error) {
                        if (!isCancelled()) {
                            console.error(`Error while backfilling "${subscription.params[0]}" subscription. Some events may be missing.`, error);
                        }
                    }
                }))();
            }
            this.startHeartbeat();
        };
        /**
         * Cancels the heartbeat and any pending backfills being performed. This is
         * called when the websocket connection goes down or is disconnected.
         *
         * This is a field arrow function in order to preserve `this` context when
         * passing the method as an event listener.
         *
         * @internal
         */
        this.stopHeartbeatAndBackfill = () => {
            if (this.heartbeatIntervalId != null) {
                clearInterval(this.heartbeatIntervalId);
                this.heartbeatIntervalId = undefined;
            }
            this.cancelBackfill();
        };
        this.apiKey = apiKey;
        // Start heartbeat and backfiller for the websocket connection.
        this.backfiller = new WebsocketBackfiller(this);
        this.addSocketListeners();
        this.startHeartbeat();
        this.cancelBackfill = noop;
    }
    /**
     * Overridden implementation of ethers' that includes Alchemy based subscriptions.
     *
     * @param eventName Event to subscribe to
     * @param listener The listener function to call when the event is triggered.
     * @override
     * @public
     */
    // TODO: Override `Listener` type to get type autocompletions.
    on(eventName, listener) {
        return this._addEventListener(eventName, listener, false);
    }
    /**
     * Overrides the method in `BaseProvider` in order to properly format the
     * Alchemy subscription events.
     *
     * @internal
     * @override
     */
    _addEventListener(eventName, listener, once) {
        if (isAlchemyEvent(eventName)) {
            const event = new EthersEvent(getAlchemyEventTag(eventName), listener, once);
            this._events.push(event);
            this._startEvent(event);
            return this;
        }
        else {
            return super._addEventListener(eventName, listener, once);
        }
    }
    /**
     * Overrides the `_startEvent()` method in ethers.js's
     * {@link WebSocketProvider} to include additional alchemy methods.
     *
     * @param event
     * @override
     * @internal
     */
    _startEvent(event) {
        // Check if the event type is a custom Alchemy subscription.
        const customLogicTypes = ['alchemy', 'block', 'filter'];
        if (customLogicTypes.includes(event.type)) {
            this.customStartEvent(event);
        }
        else {
            super._startEvent(event);
        }
    }
    /**
     * Overridden from ethers.js's {@link WebSocketProvider}
     *
     * Modified in order to add mappings for backfilling.
     *
     * @internal
     * @override
     */
    _subscribe(tag, param, processFunc, event) {
        return __awaiter(this, void 0, void 0, function* () {
            let subIdPromise = this._subIds[tag];
            // BEGIN MODIFIED CODE
            const startingBlockNumber = yield this.getBlockNumber();
            // END MODIFIED CODE
            if (subIdPromise == null) {
                subIdPromise = Promise.all(param).then(param => {
                    return this.send('eth_subscribe', param);
                });
                this._subIds[tag] = subIdPromise;
            }
            const subId = yield subIdPromise;
            // BEGIN MODIFIED CODE
            const resolvedParams = yield Promise.all(param);
            this.virtualSubscriptionsById.set(subId, {
                event: event,
                method: 'eth_subscribe',
                params: resolvedParams,
                startingBlockNumber,
                virtualId: subId,
                physicalId: subId,
                sentEvents: [],
                isBackfilling: false,
                backfillBuffer: []
            });
            this.virtualIdsByPhysicalId.set(subId, subId);
            // END MODIFIED CODE
            this._subs[subId] = { tag, processFunc };
        });
    }
    /**
     * DO NOT MODIFY.
     *
     * Original code copied over from ether.js's `BaseProvider`.
     *
     * This method is copied over directly in order to implement Alchemy's unique
     * subscription types. The only difference is that this method calls
     * {@link getAlchemyEventTag} instead of the original `getEventTag()` method in
     * order to parse the Alchemy subscription event.
     *
     * @internal
     * @override
     */
    emit(eventName, ...args) {
        if (isAlchemyEvent(eventName)) {
            let result = false;
            const stopped = [];
            // This line is the only modified line from the original method.
            const eventTag = getAlchemyEventTag(eventName);
            this._events = this._events.filter(event => {
                if (event.tag !== eventTag) {
                    return true;
                }
                setTimeout(() => {
                    event.listener.apply(this, args);
                }, 0);
                result = true;
                if (event.once) {
                    stopped.push(event);
                    return false;
                }
                return true;
            });
            stopped.forEach(event => {
                this._stopEvent(event);
            });
            return result;
        }
        else {
            return super.emit(eventName, ...args);
        }
    }
    /** @internal */
    sendBatch(parts) {
        return __awaiter(this, void 0, void 0, function* () {
            let nextId = 0;
            const payload = parts.map(({ method, params }) => {
                return {
                    method,
                    params,
                    jsonrpc: '2.0',
                    id: `alchemy-sdk:${nextId++}`
                };
            });
            const response = yield this.sendBatchConcurrently(payload);
            const errorResponse = response.find(r => !!r.error);
            if (errorResponse) {
                throw new Error(errorResponse.error.message);
            }
            // The ids are ascending numbers because that's what Payload Factories do.
            return response
                .sort((r1, r2) => r1.id - r2.id)
                .map(r => r.result);
        });
    }
    /** @override */
    destroy() {
        this.removeSocketListeners();
        this.stopHeartbeatAndBackfill();
        return super.destroy();
    }
    /**
     * Overrides the ether's `isCommunityResource()` method. Returns true if the
     * current api key is the default key.
     *
     * @override
     */
    isCommunityResource() {
        return this.apiKey === DEFAULT_ALCHEMY_API_KEY;
    }
    /** @internal */
    addSocketListeners() {
        this._websocket.addEventListener('message', this.handleMessage);
        this._websocket.addEventListener('reopen', this.handleReopen);
        this._websocket.addEventListener('down', this.stopHeartbeatAndBackfill);
    }
    /** @internal */
    removeSocketListeners() {
        this._websocket.removeEventListener('message', this.handleMessage);
        this._websocket.removeEventListener('reopen', this.handleReopen);
        this._websocket.removeEventListener('down', this.stopHeartbeatAndBackfill);
    }
    /**
     * Reopens the backfill based on
     *
     * @param isCancelled
     * @param subscription
     * @internal
     */
    resubscribeAndBackfill(isCancelled, subscription) {
        return __awaiter(this, void 0, void 0, function* () {
            const { virtualId, method, params, sentEvents, backfillBuffer, startingBlockNumber } = subscription;
            subscription.isBackfilling = true;
            backfillBuffer.length = 0;
            try {
                const physicalId = yield this.send(method, params);
                throwIfCancelled(isCancelled);
                subscription.physicalId = physicalId;
                this.virtualIdsByPhysicalId.set(physicalId, virtualId);
                switch (params[0]) {
                    case 'newHeads': {
                        const backfillEvents = yield withBackoffRetries(() => withTimeout(this.backfiller.getNewHeadsBackfill(isCancelled, sentEvents, startingBlockNumber), BACKFILL_TIMEOUT), BACKFILL_RETRIES, () => !isCancelled());
                        throwIfCancelled(isCancelled);
                        const events = dedupeNewHeads([...backfillEvents, ...backfillBuffer]);
                        events.forEach(event => this.emitNewHeadsEvent(virtualId, event));
                        break;
                    }
                    case 'logs': {
                        const filter = params[1] || {};
                        const backfillEvents = yield withBackoffRetries(() => withTimeout(this.backfiller.getLogsBackfill(isCancelled, filter, sentEvents, startingBlockNumber), BACKFILL_TIMEOUT), BACKFILL_RETRIES, () => !isCancelled());
                        throwIfCancelled(isCancelled);
                        const events = dedupeLogs([...backfillEvents, ...backfillBuffer]);
                        events.forEach(event => this.emitLogsEvent(virtualId, event));
                        break;
                    }
                    default:
                        break;
                }
            }
            finally {
                subscription.isBackfilling = false;
                backfillBuffer.length = 0;
            }
        });
    }
    /** @internal */
    emitNewHeadsEvent(virtualId, result) {
        this.emitAndRememberEvent(virtualId, result, getNewHeadsBlockNumber);
    }
    /** @internal */
    emitLogsEvent(virtualId, result) {
        this.emitAndRememberEvent(virtualId, result, getLogsBlockNumber);
    }
    /**
     * Emits an event to consumers, but also remembers it in its subscriptions's
     * `sentEvents` buffer so that we can detect re-orgs if the connection drops
     * and needs to be reconnected.
     *
     * @internal
     */
    emitAndRememberEvent(virtualId, result, getBlockNumber) {
        this.rememberEvent(virtualId, result, getBlockNumber);
        const subscription = this.virtualSubscriptionsById.get(virtualId);
        if (!subscription) {
            return;
        }
        this.emitGenericEvent(subscription, result);
    }
    /** @internal */
    rememberEvent(virtualId, result, getBlockNumber) {
        const subscription = this.virtualSubscriptionsById.get(virtualId);
        if (!subscription) {
            return;
        }
        // Web3 modifies these event objects once we pass them on (changing hex
        // numbers to numbers). We want the original event, so make a defensive
        // copy.
        addToPastEventsBuffer(subscription.sentEvents, Object.assign({}, result), getBlockNumber);
    }
    /** @internal */
    emitGenericEvent(subscription, result) {
        const emitFunction = this.emitProcessFn(subscription.event);
        emitFunction(result);
    }
    /**
     * Starts a heartbeat that pings the websocket server periodically to ensure
     * that the connection stays open.
     *
     * @internal
     */
    startHeartbeat() {
        if (this.heartbeatIntervalId != null) {
            return;
        }
        this.heartbeatIntervalId = setInterval(() => __awaiter(this, void 0, void 0, function* () {
            try {
                yield withTimeout(this.send('net_version'), HEARTBEAT_WAIT_TIME);
            }
            catch (_a) {
                this._websocket.reconnect();
            }
        }), HEARTBEAT_INTERVAL);
    }
    /**
     * This method sends the batch concurrently as individual requests rather than
     * as a batch, which was the original implementation. The original batch logic
     * is preserved in this implementation in order for faster porting.
     *
     * @param payload
     * @internal
     */
    // TODO(cleanup): Refactor and remove usages of `sendBatch()`.
    // TODO(errors): Use allSettled() once we have more error handling.
    sendBatchConcurrently(payload) {
        return __awaiter(this, void 0, void 0, function* () {
            return Promise.all(payload.map(req => this.send(req.method, req.params)));
        });
    }
    /** @internal */
    customStartEvent(event) {
        if (event.type === 'alchemy') {
            const { address } = event;
            if (!!address) {
                void this._subscribe(event.tag, ['alchemy_filteredNewFullPendingTransactions', { address }], this.emitProcessFn(event), event);
            }
            else {
                void this._subscribe(event.tag, ['alchemy_newFullPendingTransactions'], this.emitProcessFn(event), event);
            }
        }
        else if (event.type === 'block') {
            void this._subscribe('block', ['newHeads'], this.emitProcessFn(event), event);
        }
        else if (event.type === 'filter') {
            void this._subscribe(event.tag, ['logs', this._getFilter(event.filter)], this.emitProcessFn(event), event);
        }
    }
    /** @internal */
    emitProcessFn(event) {
        switch (event.type) {
            case 'alchemy':
                const { address } = event;
                if (!!address) {
                    return result => this.emit({
                        method: 'alchemy_filteredNewFullPendingTransactions',
                        address: event.address
                    }, result);
                }
                else {
                    return result => this.emit({ method: 'alchemy_newFullPendingTransactions' }, result);
                }
            case 'block':
                return result => {
                    const blockNumber = BigNumber.from(result.number).toNumber();
                    this._emitted.block = blockNumber;
                    this.emit('block', blockNumber);
                };
            case 'filter':
                return result => {
                    if (result.removed == null) {
                        result.removed = false;
                    }
                    this.emit(event.filter, this.formatter.filterLog(result));
                };
            default:
                throw new Error('Invalid event type to `emitProcessFn()`');
        }
    }
}
function getWebsocketConstructor() {
    return isNodeEnvironment() ? require('websocket').w3cwebsocket : WebSocket;
}
function isNodeEnvironment() {
    return (typeof process !== 'undefined' &&
        process != null &&
        process.versions != null &&
        process.versions.node != null);
}
// TODO(cleanup): Use class variable rather than passing `isCancelled` everywhere.
function makeCancelToken() {
    let cancelled = false;
    return { cancel: () => (cancelled = true), isCancelled: () => cancelled };
}
// TODO(cleanup): replace with SDK's backoff implementation
const MIN_RETRY_DELAY = 1000;
const RETRY_BACKOFF_FACTOR = 2;
const MAX_RETRY_DELAY = 30000;
function withBackoffRetries(f, retryCount, shouldRetry = () => true) {
    return __awaiter(this, void 0, void 0, function* () {
        let nextWaitTime = 0;
        let i = 0;
        while (true) {
            try {
                return yield f();
            }
            catch (error) {
                i++;
                if (i >= retryCount || !shouldRetry(error)) {
                    throw error;
                }
                yield delay(nextWaitTime);
                if (!shouldRetry(error)) {
                    throw error;
                }
                nextWaitTime =
                    nextWaitTime === 0
                        ? MIN_RETRY_DELAY
                        : Math.min(MAX_RETRY_DELAY, RETRY_BACKOFF_FACTOR * nextWaitTime);
            }
        }
    });
}
function delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
}
function withTimeout(promise, ms) {
    return Promise.race([
        promise,
        new Promise((_, reject) => setTimeout(() => reject(new Error('Timeout')), ms))
    ]);
}
function getNewHeadsBlockNumber(event) {
    return fromHex(event.number);
}
function getLogsBlockNumber(event) {
    return fromHex(event.blockNumber);
}
function isResponse(message) {
    return (Array.isArray(message) ||
        (message.jsonrpc === '2.0' && message.id !== undefined));
}
function isSubscriptionEvent(message) {
    return !isResponse(message);
}
function addToNewHeadsEventsBuffer(pastEvents, event) {
    addToPastEventsBuffer(pastEvents, event, getNewHeadsBlockNumber);
}
function addToLogsEventsBuffer(pastEvents, event) {
    addToPastEventsBuffer(pastEvents, event, getLogsBlockNumber);
}
/**
 * Adds a new event to an array of events, evicting any events which are so old
 * that they will no longer feasibly be part of a reorg.
 */
function addToPastEventsBuffer(pastEvents, event, getBlockNumber) {
    const currentBlockNumber = getBlockNumber(event);
    // Find first index of an event recent enough to retain, then drop everything
    // at a lower index.
    const firstGoodIndex = pastEvents.findIndex(e => getBlockNumber(e) > currentBlockNumber - RETAINED_EVENT_BLOCK_COUNT);
    if (firstGoodIndex === -1) {
        pastEvents.length = 0;
    }
    else {
        pastEvents.splice(0, firstGoodIndex);
    }
    pastEvents.push(event);
}
function isAlchemyEvent(event) {
    return typeof event === 'object' && 'method' in event;
}
function getAlchemyEventTag(event) {
    if (!isAlchemyEvent(event)) {
        throw new Error('Event tag requires AlchemyEventType');
    }
    return 'alchemy:' + (('address' in event && event.address) || '*');
}

/**
 * Entry point into the Alchemy SDK.
 *
 * @param config - Configuration object for the Alchemy SDK
 * @public
 */
function initializeAlchemy(config) {
    return new Alchemy(config);
}
/**
 * The Alchemy SDK client. This class holds config information and must be
 * passed into SDK methods.
 *
 * Do not call this constructor directly. Instead, use {@link initializeAlchemy}
 * to get an instance of the SDK.
 *
 * @public
 */
class Alchemy {
    /**
     * @hideconstructor
     * @internal
     */
    constructor(config) {
        this.apiKey = (config === null || config === void 0 ? void 0 : config.apiKey) || DEFAULT_ALCHEMY_API_KEY;
        this.network = (config === null || config === void 0 ? void 0 : config.network) || DEFAULT_NETWORK;
        this.maxRetries = (config === null || config === void 0 ? void 0 : config.maxRetries) || DEFAULT_MAX_RETRIES;
    }
    /** @internal */
    getBaseUrl() {
        return getAlchemyHttpUrl(this.network, this.apiKey);
    }
    /** @internal */
    getNftUrl() {
        return getAlchemyNftHttpUrl(this.network, this.apiKey);
    }
    /**
     * Changes the network that the SDK requests data from.
     *
     * @param network - The network to change to.
     * @public
     */
    setNetwork(network) {
        // TODO(ethers): Add support for changing the network in the returned provider.
        this.network = network;
    }
    /**
     * Creates an AlchemyProvider instance. Only one provider is created per
     * Alchemy instance.
     *
     * @public
     */
    getProvider() {
        if (!this._baseAlchemyProvider) {
            this._baseAlchemyProvider = new AlchemyProvider(this.network, this.apiKey, this.maxRetries);
        }
        return this._baseAlchemyProvider;
    }
    /**
     * Creates an AlchemyWebsocketProvider instance. Only one provider is created
     * per Alchemy instance.
     *
     * @public
     */
    getWebsocketProvider() {
        if (!this._baseAlchemyWssProvider) {
            this._baseAlchemyWssProvider = new AlchemyWebSocketProvider(this.network, this.apiKey);
        }
        return this._baseAlchemyWssProvider;
    }
}

/**
 * Given a REST endpoint, method, and params, sends the request with axios and
 * returns the response.
 */
const IS_BROWSER = typeof window !== 'undefined' && window !== null;
/**
 * Helper function to send http requests using Axis.
 *
 * @private
 */
// TODO: Support other methods besides GET + other http options.
function sendAxiosRequest(baseUrl, methodName, params) {
    const methodUrl = baseUrl + '/' + methodName;
    const config = {
        headers: IS_BROWSER
            ? {
                'Alchemy-Ethers-Sdk-Version': VERSION
            }
            : {
                'Alchemy-Ethers-Sdk-Version': VERSION,
                'Accept-Encoding': 'gzip'
            },
        method: 'get',
        url: methodUrl,
        params
    };
    return axios(config);
}

const DEFAULT_BACKOFF_INITIAL_DELAY_MS = 1000;
const DEFAULT_BACKOFF_MULTIPLIER = 1.5;
const DEFAULT_BACKOFF_MAX_DELAY_MS = 30 * 1000;
const DEFAULT_BACKOFF_MAX_ATTEMPTS = 5;
/**
 * Helper class for implementing exponential backoff and max retry attempts.
 *
 * @private
 * @internal
 */
class ExponentialBackoff {
    constructor(maxAttempts = DEFAULT_BACKOFF_MAX_ATTEMPTS) {
        this.maxAttempts = maxAttempts;
        this.initialDelayMs = DEFAULT_BACKOFF_INITIAL_DELAY_MS;
        this.backoffMultiplier = DEFAULT_BACKOFF_MULTIPLIER;
        this.maxDelayMs = DEFAULT_BACKOFF_MAX_DELAY_MS;
        this.numAttempts = 0;
        this.currentDelayMs = 0;
        this.isInBackoff = false;
    }
    /**
     * Returns a promise that resolves after the the backoff delay. The delay is
     * increased for each attempt. The promise is rejected if the maximum number
     * of attempts is exceeded.
     */
    // TODO: beautify this into an async iterator.
    backoff() {
        if (this.numAttempts >= this.maxAttempts) {
            return Promise.reject(new Error(`Exceeded maximum number of attempts: ${this.maxAttempts}`));
        }
        if (this.isInBackoff) {
            return Promise.reject(new Error('A backoff operation is already in progress'));
        }
        const backoffDelayWithJitterMs = this.withJitterMs(this.currentDelayMs);
        if (backoffDelayWithJitterMs > 0) {
            logDebug('ExponentialBackoff.backoff', `Backing off for ${backoffDelayWithJitterMs}ms`);
        }
        // Calculate the next delay.
        this.currentDelayMs *= this.backoffMultiplier;
        this.currentDelayMs = Math.max(this.currentDelayMs, this.initialDelayMs);
        this.currentDelayMs = Math.min(this.currentDelayMs, this.maxDelayMs);
        this.numAttempts += 1;
        return new Promise(resolve => {
            this.isInBackoff = true;
            setTimeout(() => {
                this.isInBackoff = false;
                resolve();
            }, backoffDelayWithJitterMs);
        });
    }
    /**
     * Applies +/- 50% jitter to the backoff delay, up to the max delay cap.
     *
     * @private
     * @param delayMs
     */
    withJitterMs(delayMs) {
        return Math.min(delayMs + (Math.random() - 0.5) * delayMs, this.maxDelayMs);
    }
}

/**
 * A wrapper function to make http requests and retry if the request fails.
 *
 * @param alchemy
 * @param method
 * @param params
 * @internal
 */
// TODO: Wrap Axios error in AlchemyError.
function requestHttpWithBackoff(alchemy, apiType, method, params) {
    return __awaiter(this, void 0, void 0, function* () {
        let lastError = undefined;
        const backoff = new ExponentialBackoff(alchemy.maxRetries);
        for (let attempt = 0; attempt < alchemy.maxRetries + 1; attempt++) {
            try {
                if (lastError !== undefined) {
                    logInfo('requestHttp', `Retrying after error: ${lastError.message}`);
                }
                try {
                    yield backoff.backoff();
                }
                catch (err) {
                    // Backoff errors when the maximum number of attempts is reached. Break
                    // out of the loop to preserve the last error.
                    break;
                }
                let response;
                switch (apiType) {
                    case AlchemyApiType.NFT:
                        response = yield sendAxiosRequest(alchemy.getNftUrl(), method, params);
                        break;
                    default:
                    case AlchemyApiType.BASE:
                        response = yield sendAxiosRequest(alchemy.getBaseUrl(), method, params);
                        break;
                }
                if (response.status === 200) {
                    logDebug(method, `Successful request: ${method}`);
                    return response.data;
                }
                else {
                    logInfo(method, `Request failed: ${method}, ${response.status}, ${response.data}`);
                    lastError = new Error(response.status + ': ' + response.data);
                }
            }
            catch (err) {
                if (!axios.isAxiosError(err) || err.response === undefined) {
                    throw err;
                }
                // TODO: Standardize all errors into AlchemyError
                lastError = new Error(err.response.status + ': ' + err.response.data);
                if (!isRetryableHttpError(err)) {
                    break;
                }
            }
        }
        return Promise.reject(lastError);
    });
}
function isRetryableHttpError(err) {
    const retryableCodes = [429];
    return (err.response !== undefined && retryableCodes.includes(err.response.status));
}
/**
 * Fetches all pages in a paginated endpoint, given a `pageKey` field that
 * represents the property name containing the next page token.
 *
 * @internal
 */
function paginateEndpoint(alchemy, apiType, methodName, reqPageKey, resPageKey, params) {
    return __asyncGenerator(this, arguments, function* paginateEndpoint_1() {
        let hasNext = true;
        const requestParams = Object.assign({}, params);
        while (hasNext) {
            const response = yield __await(requestHttpWithBackoff(alchemy, apiType, methodName, requestParams));
            yield yield __await(response);
            if (response[resPageKey] !== undefined) {
                requestParams[reqPageKey] = response[resPageKey];
            }
            else {
                hasNext = false;
            }
        }
    });
}

function formatBlock(block) {
    if (typeof block === 'string') {
        return block;
    }
    else if (Number.isInteger(block)) {
        return toHex(block);
    }
    return block.toString();
}
function getNftContractFromRaw(rawNftContract) {
    return {
        address: rawNftContract.address,
        name: rawNftContract.contractMetadata.name,
        symbol: rawNftContract.contractMetadata.symbol,
        totalSupply: rawNftContract.contractMetadata.totalSupply,
        tokenType: parseNftTokenType(rawNftContract.contractMetadata.tokenType)
    };
}
function getBaseNftFromRaw(rawBaseNft, contractAddress) {
    var _a;
    return {
        contract: { address: contractAddress },
        tokenId: BigNumber.from(rawBaseNft.id.tokenId).toString(),
        tokenType: parseNftTokenType((_a = rawBaseNft.id.tokenMetadata) === null || _a === void 0 ? void 0 : _a.tokenType)
    };
}
function getNftFromRaw(rawNft, contractAddress) {
    var _a;
    return {
        contract: { address: contractAddress },
        tokenId: parseNftTokenId(rawNft.id.tokenId),
        tokenType: parseNftTokenType((_a = rawNft.id.tokenMetadata) === null || _a === void 0 ? void 0 : _a.tokenType),
        title: rawNft.title,
        description: parseNftDescription(rawNft.description),
        timeLastUpdated: rawNft.timeLastUpdated,
        metadataError: rawNft.error,
        rawMetadata: rawNft.metadata,
        tokenUri: parseNftTokenUri(rawNft.tokenUri),
        media: parseNftTokenUriArray(rawNft.media)
    };
}
function parseNftTokenId(tokenId) {
    // We have to normalize the token id here since the backend sometimes
    // returns the token ID as a hex string and sometimes as an integer.
    return BigNumber.from(tokenId).toString();
}
function parseNftTokenType(tokenType) {
    switch (tokenType) {
        case 'erc721':
        case 'ERC721':
            return NftTokenType.ERC721;
        case 'erc1155':
        case 'ERC1155':
            return NftTokenType.ERC1155;
        default:
            return NftTokenType.UNKNOWN;
    }
}
function parseNftDescription(description) {
    if (description === undefined) {
        return '';
    }
    return typeof description === 'string' ? description : description.join(' ');
}
function parseNftTokenUri(uri) {
    if (uri && uri.raw.length === 0 && uri.gateway.length == 0) {
        return undefined;
    }
    return uri;
}
function parseNftTokenUriArray(arr) {
    if (arr === undefined) {
        return [];
    }
    return arr.filter(uri => parseNftTokenUri(uri) !== undefined);
}

/** @public */
function getTokenBalances(alchemy, address, contractAddresses) {
    if (contractAddresses && contractAddresses.length > 1500) {
        throw new Error('You cannot pass in more than 1500 contract addresses to getTokenBalances()');
    }
    return alchemy
        .getProvider()
        .send('alchemy_getTokenBalances', [
        address,
        contractAddresses || DEFAULT_CONTRACT_ADDRESSES
    ]);
}
/** @public */
function getTokenMetadata(alchemy, address) {
    return alchemy.getProvider().send('alchemy_getTokenMetadata', [address]);
}
/** @public */
function getAssetTransfers(alchemy, params) {
    return alchemy.getProvider().send('alchemy_getAssetTransfers', [
        Object.assign(Object.assign({}, params), { fromBlock: params.fromBlock != null ? formatBlock(params.fromBlock) : undefined, toBlock: params.toBlock != null ? formatBlock(params.toBlock) : undefined, maxCount: params.maxCount != null ? toHex(params.maxCount) : undefined })
    ]);
}
/** @public */
function getTransactionReceipts(alchemy, params) {
    return alchemy.getProvider().send('alchemy_getTransactionReceipts', [params]);
}

const ETH_NULL_VALUE = '0x';
function getNftMetadata(alchemy, contractAddressOrBaseNft, tokenId, tokenType) {
    return __awaiter(this, void 0, void 0, function* () {
        let response;
        let contractAddress;
        if (typeof contractAddressOrBaseNft === 'string') {
            contractAddress = contractAddressOrBaseNft;
            response = yield requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getNFTMetadata', {
                contractAddress: contractAddressOrBaseNft,
                tokenId: BigNumber.from(tokenId).toString(),
                tokenType: tokenType !== NftTokenType.UNKNOWN ? tokenType : undefined
            });
        }
        else {
            contractAddress = contractAddressOrBaseNft.contract.address;
            response = yield requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getNFTMetadata', {
                contractAddress: contractAddressOrBaseNft.contract.address,
                tokenId: BigNumber.from(contractAddressOrBaseNft.tokenId).toString(),
                tokenType: contractAddressOrBaseNft.tokenType !== NftTokenType.UNKNOWN
                    ? contractAddressOrBaseNft.tokenType
                    : undefined
            });
        }
        return getNftFromRaw(response, contractAddress);
    });
}
function getNftContractMetadata(alchemy, contractAddressOrBaseNftContract) {
    return __awaiter(this, void 0, void 0, function* () {
        let response;
        if (typeof contractAddressOrBaseNftContract === 'string') {
            response = yield requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getContractMetadata', {
                contractAddress: contractAddressOrBaseNftContract
            });
        }
        else {
            response = yield requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getContractMetadata', {
                contractAddress: contractAddressOrBaseNftContract.address
            });
        }
        return getNftContractFromRaw(response);
    });
}
function getNftsForOwnerIterator(alchemy, owner, options) {
    return __asyncGenerator(this, arguments, function* getNftsForOwnerIterator_1() {
        var e_1, _a;
        const withMetadata = omitMetadataToWithMetadata(options === null || options === void 0 ? void 0 : options.omitMetadata);
        try {
            for (var _b = __asyncValues(paginateEndpoint(alchemy, AlchemyApiType.NFT, 'getNFTs', 'pageKey', 'pageKey', {
                contractAddresses: options === null || options === void 0 ? void 0 : options.contractAddresses,
                pageKey: options === null || options === void 0 ? void 0 : options.pageKey,
                filters: options === null || options === void 0 ? void 0 : options.excludeFilters,
                owner,
                withMetadata
            })), _c; _c = yield __await(_b.next()), !_c.done;) {
                const response = _c.value;
                for (const ownedNft of response.ownedNfts) {
                    yield yield __await(Object.assign(Object.assign({}, nftFromGetNftResponse(ownedNft)), { balance: parseInt(ownedNft.balance) }));
                }
            }
        }
        catch (e_1_1) { e_1 = { error: e_1_1 }; }
        finally {
            try {
                if (_c && !_c.done && (_a = _b.return)) yield __await(_a.call(_b));
            }
            finally { if (e_1) throw e_1.error; }
        }
    });
}
function getNftsForOwner(alchemy, owner, options) {
    return __awaiter(this, void 0, void 0, function* () {
        const withMetadata = omitMetadataToWithMetadata(options === null || options === void 0 ? void 0 : options.omitMetadata);
        const response = yield requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getNFTs', {
            contractAddresses: options === null || options === void 0 ? void 0 : options.contractAddresses,
            pageKey: options === null || options === void 0 ? void 0 : options.pageKey,
            filters: options === null || options === void 0 ? void 0 : options.excludeFilters,
            owner,
            withMetadata
        });
        return {
            ownedNfts: response.ownedNfts.map(res => (Object.assign(Object.assign({}, nftFromGetNftResponse(res)), { balance: parseInt(res.balance) }))),
            pageKey: response.pageKey,
            totalCount: response.totalCount
        };
    });
}
function getNftsForCollection(alchemy, contractAddress, options) {
    return __awaiter(this, void 0, void 0, function* () {
        const withMetadata = omitMetadataToWithMetadata(options === null || options === void 0 ? void 0 : options.omitMetadata);
        const response = yield requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getNFTsForCollection', {
            contractAddress,
            startToken: options === null || options === void 0 ? void 0 : options.pageKey,
            withMetadata
        });
        return {
            nfts: response.nfts.map(res => nftFromGetNftCollectionResponse(res, contractAddress)),
            pageKey: response.nextToken
        };
    });
}
function getOwnersForNft(alchemy, contractAddressOrNft, tokenId) {
    if (typeof contractAddressOrNft === 'string') {
        return requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getOwnersForToken', {
            contractAddress: contractAddressOrNft,
            tokenId: BigNumber.from(tokenId).toString()
        });
    }
    else {
        return requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getOwnersForToken', {
            contractAddress: contractAddressOrNft.contract.address,
            tokenId: BigNumber.from(contractAddressOrNft.tokenId).toString()
        });
    }
}
function getOwnersForCollection(alchemy, contractAddressOrNft) {
    return __awaiter(this, void 0, void 0, function* () {
        let response;
        if (typeof contractAddressOrNft === 'string') {
            response = yield requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getOwnersForCollection', {
                contractAddress: contractAddressOrNft
            });
        }
        else {
            response = yield requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getOwnersForCollection', {
                contractAddress: contractAddressOrNft.contract.address
            });
        }
        return {
            owners: response.ownerAddresses
        };
    });
}
function getNftsForCollectionIterator(alchemy, contractAddress, options) {
    return __asyncGenerator(this, arguments, function* getNftsForCollectionIterator_1() {
        var e_2, _a;
        const withMetadata = omitMetadataToWithMetadata(options === null || options === void 0 ? void 0 : options.omitMetadata);
        try {
            for (var _b = __asyncValues(paginateEndpoint(alchemy, AlchemyApiType.NFT, 'getNFTsForCollection', 'startToken', 'nextToken', {
                contractAddress,
                startToken: options === null || options === void 0 ? void 0 : options.pageKey,
                withMetadata
            })), _c; _c = yield __await(_b.next()), !_c.done;) {
                const response = _c.value;
                for (const nft of response.nfts) {
                    yield yield __await(nftFromGetNftCollectionResponse(nft, contractAddress));
                }
            }
        }
        catch (e_2_1) { e_2 = { error: e_2_1 }; }
        finally {
            try {
                if (_c && !_c.done && (_a = _b.return)) yield __await(_a.call(_b));
            }
            finally { if (e_2) throw e_2.error; }
        }
    });
}
/**
 * Checks that the provided owner address owns one of more of the provided NFTs.
 *
 * @param alchemy - The Alchemy SDK instance.
 * @param owner - The owner address to check.
 * @param contractAddresses - An array of NFT contract addresses to check ownership for.
 * @beta
 */
function checkNftOwnership(alchemy, owner, contractAddresses) {
    return __awaiter(this, void 0, void 0, function* () {
        if (contractAddresses.length === 0) {
            throw new Error('Must provide at least one contract address');
        }
        const response = yield getNftsForOwner(alchemy, owner, {
            contractAddresses,
            omitMetadata: true
        });
        return response.ownedNfts.length > 0;
    });
}
/**
 * Returns whether a contract is marked as spam or not by Alchemy. For more
 * information on how we classify spam, go to our NFT API FAQ at
 * https://docs.alchemy.com/alchemy/enhanced-apis/nft-api/nft-api-faq#nft-spam-classification.
 *
 * @param alchemy - The Alchemy SDK instance.
 * @param contractAddress - The contract address to check.
 * @beta
 */
function isSpamNftContract(alchemy, contractAddress) {
    return __awaiter(this, void 0, void 0, function* () {
        return requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'isSpamContract', {
            contractAddress
        });
    });
}
/**
 * Returns a list of all spam contracts marked by Alchemy. For details on how
 * Alchemy marks spam contracts, go to
 * https://docs.alchemy.com/alchemy/enhanced-apis/nft-api/nft-api-faq#nft-spam-classification.
 *
 * @param alchemy - The Alchemy SDK instance.
 * @beta
 */
function getSpamNftContracts(alchemy) {
    return __awaiter(this, void 0, void 0, function* () {
        return requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getSpamContracts', undefined);
    });
}
/**
 * Returns the floor prices of a NFT contract by marketplace.
 *
 * @param alchemy - The Alchemy SDK instance.
 * @param contractAddress - The contract address for the NFT collection.
 * @beta
 */
function getNftFloorPrice(alchemy, contractAddress) {
    return __awaiter(this, void 0, void 0, function* () {
        return requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getFloorPrice', {
            contractAddress
        });
    });
}
/**
 * Finds the address that deployed the provided contract and block number it was
 * deployed in.
 *
 * NOTE: This method performs a binary search across all blocks since genesis
 * and can take a long time to complete. This method is a convenience method
 * that will eventually be replaced by a single call to an Alchemy endpoint with
 * this information cached.
 *
 * @param alchemy - The Alchemy SDK instance.
 * @param contractAddress - The contract address to find the deployer for.
 * @beta
 */
function findContractDeployer(alchemy, contractAddress) {
    var _a;
    return __awaiter(this, void 0, void 0, function* () {
        const provider = alchemy.getProvider();
        const currentBlockNum = yield provider.getBlockNumber();
        if ((yield provider.getCode(contractAddress, currentBlockNum)) ===
            ETH_NULL_VALUE) {
            throw new Error(`Contract '${contractAddress}' does not exist`);
        }
        // Binary search for the block number that the contract was deployed in.
        const firstBlock = yield binarySearchFirstBlock(0, currentBlockNum + 1, contractAddress, alchemy);
        // Find the first transaction in the block that matches the provided address.
        const txReceipts = yield getTransactionReceipts(alchemy, {
            blockNumber: toHex(firstBlock)
        });
        const matchingReceipt = (_a = txReceipts.receipts) === null || _a === void 0 ? void 0 : _a.find(receipt => receipt.contractAddress === contractAddress.toLowerCase());
        return {
            deployerAddress: matchingReceipt === null || matchingReceipt === void 0 ? void 0 : matchingReceipt.from,
            blockNumber: firstBlock
        };
    });
}
function refreshNftMetadata(alchemy, contractAddressOrBaseNft, tokenId) {
    return __awaiter(this, void 0, void 0, function* () {
        let contractAddress;
        let tokenIdString;
        if (typeof contractAddressOrBaseNft === 'string') {
            contractAddress = contractAddressOrBaseNft;
            tokenIdString = BigNumber.from(tokenId).toString();
        }
        else {
            contractAddress = contractAddressOrBaseNft.contract.address;
            tokenIdString = contractAddressOrBaseNft.tokenId;
        }
        const first = yield getNftMetadata(alchemy, contractAddress, tokenIdString);
        const second = yield refresh(alchemy, contractAddress, tokenIdString);
        return first.timeLastUpdated !== second.timeLastUpdated;
    });
}
function refresh(alchemy, contractAddress, tokenId) {
    return __awaiter(this, void 0, void 0, function* () {
        const response = yield requestHttpWithBackoff(alchemy, AlchemyApiType.NFT, 'getNFTMetadata', {
            contractAddress,
            tokenId: BigNumber.from(tokenId).toString(),
            refreshCache: true
        });
        return getNftFromRaw(response, contractAddress);
    });
}
/**
 * Perform a binary search between an integer range of block numbers to find the
 * block number where the contract was deployed.
 *
 * @internal
 */
function binarySearchFirstBlock(start, end, address, alchemy) {
    return __awaiter(this, void 0, void 0, function* () {
        if (start >= end) {
            return end;
        }
        const mid = Math.floor((start + end) / 2);
        const code = yield alchemy.getProvider().getCode(address, mid);
        if (code === ETH_NULL_VALUE) {
            return binarySearchFirstBlock(mid + 1, end, address, alchemy);
        }
        return binarySearchFirstBlock(start, mid, address, alchemy);
    });
}
/**
 * Helper method to convert a NFT response received from Alchemy backend to an
 * SDK NFT type.
 *
 * @internal
 */
function nftFromGetNftResponse(ownedNft) {
    if (isNftWithMetadata(ownedNft)) {
        return getNftFromRaw(ownedNft, ownedNft.contract.address);
    }
    else {
        return getBaseNftFromRaw(ownedNft, ownedNft.contract.address);
    }
}
/**
 * Helper method to convert a NFT response received from Alchemy backend to an
 * SDK NFT type.
 *
 * @internal
 */
function nftFromGetNftCollectionResponse(ownedNft, contractAddress) {
    if (isNftWithMetadata(ownedNft)) {
        return getNftFromRaw(ownedNft, contractAddress);
    }
    else {
        return getBaseNftFromRaw(ownedNft, contractAddress);
    }
}
/** @internal */
// TODO: more comprehensive type check
function isNftWithMetadata(response) {
    return response.title !== undefined;
}
/**
 * Flips the `omitMetadata` SDK parameter type to the `withMetadata` parameter
 * required by the Alchemy API. If `omitMetadata` is undefined, the SDK defaults
 * to including metadata.
 *
 * @internal
 */
function omitMetadataToWithMetadata(omitMetadata) {
    return omitMetadata === undefined ? true : !omitMetadata;
}

export { Alchemy, AlchemyProvider, AlchemyWebSocketProvider, AssetTransfersCategory, AssetTransfersOrder, Network, NftExcludeFilters, NftTokenType, checkNftOwnership, findContractDeployer, fromHex, getAssetTransfers, getNftContractMetadata, getNftFloorPrice, getNftMetadata, getNftsForCollection, getNftsForCollectionIterator, getNftsForOwner, getNftsForOwnerIterator, getOwnersForCollection, getOwnersForNft, getSpamNftContracts, getTokenBalances, getTokenMetadata, getTransactionReceipts, initializeAlchemy, isHex, isSpamNftContract, refreshNftMetadata, setLogLevel, toHex };
//# sourceMappingURL=index.esm.js.map
